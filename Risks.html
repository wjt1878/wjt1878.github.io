<!DOCTYPE HTML>
<!--
	Massively by HTML5 UP
	html5up.net | @ajlkn
	Free for personal and commercial use under the CCA 3.0 license (html5up.net/license)
-->
<html>
	<head>
		<title>Generic Page - Massively by HTML5 UP</title>
		<meta charset="utf-8" />
		<meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no" />
		<link rel="stylesheet" href="assets/css/main.css" />
		<noscript><link rel="stylesheet" href="assets/css/noscript.css" /></noscript>
	</head>
	<body class="is-preload">

		<!-- Wrapper -->
			<div id="wrapper">

				<!-- Header -->
					<header id="header">
					</header>

				<!-- Nav -->
					<nav id="nav">
						<ul class="links">
							<li class="active"><a href="index.html">Home</a></li>
							<li class="active"><a href="XAI.html">XAI</a></li>
							<li class="active"><a href="Opportunities.html">Opportunities</a></li>
							<li class="active"><a href="Risks.html">Risks</a></li>
							<li class="active"><a href="Choices.html">Choices</a></li>
							<li class="active"><a href="Ethics.html">Ethics</a></li>
							<li class="active"><a href="References.html">References</a></li>
							<li class="active"><a href="Process Support.html">Process Support</a></li>	
						</ul>
						<ul class="icons">
							<li><a href="#" class="icon brands fa-github"><span class="label">GitHub</span></a></li>
						</ul>
					</nav>

				<!-- Main -->
					<div id="main">

						<!-- Post -->
							<section class="post">
								<header class="major">
									<span class="date">April 25, 2017</span>
									<h1>Risks</h1>
									<p>Uncover the possible risks and obstacles of Explainable AI,<br />
									such as the balance between performance and interpretability,<br />
									the possibility of biassed or manipulated explanations, and concerns <br />
									regarding security, privacy, and data protection.</p>
								</header>
								<div class="image main"><img src="images/bug.jpg" alt="" /></div>
								<h3>Risk 1:</h3>
								<p>One particular risk is the exchange between performance & interpretability of AI systems. A study addresses this issue by emphasising the prospect of compromising anticipated precision & performance as AI models become progressively interpretable. This risk occurs due to the process of rendering complex AI models to be simpler or integrating interpretability methods, which could result in a loss of complexity and intricate functionalities, potentially affecting the performance of the AI model (Rudin, 2019.) The extent of interpretability for an AI machine depends on the application & the stakeholders involved. Enhanced interpretability is necessary for legal conformity and accountability in specific industries, including finance or healthcare. Interpretability might not be as important as performance in other domains like natural language processing or recognition of images </p>
								<h3>Risk 2:</h3>
								<p>The ability for explanations to be manipulated presents as another risk. The potential risk of XAI in this situation is that, despite the application of interpretability techniques, fundamental ethical problems could remain in the algorithms or the "training" data. A study emphasises the significance of thoroughly considering both the principles ingrained in algorithms and any inherent discrimination, prejudices, and unforeseen outcomes that may result from utilising it (Mittelstadt et al., 2016). Furthermore, It highlights the necessity of continuous investigation, openness, and open discussion to make sure that the creation and application of AI systems, including XAI, are ethically acceptable and consistent with social expectations. Companies who use XAI could risk legal repercussions and harm to their reputation if explanations are used maliciously, for instance to propagate false information or influence user behaviour.</p>
								<h3>Risk 3:</h3>
								<p>Concerns exist with relation to security & privacy. Numerous data sets are accessed & analysed by XAI, which could create privacy concerns and the possibility of unauthorised access to or exploitation of sensitive data. When hackers capitalise on the flaws in XAI systems' justifications, there's a risk of obtaining access to systems without authorisation or changing how they operate. Moreover, If the AI systems explanations expose private or distinctly identifiable information, privacy laws could be breached or people could be put in danger (Mothukuri et al., 2021). For companies who wish to implement XAI, the risks associated with XAI's security flaws, privacy invasions, and data leaking could be severe. Such risks consist of the potential for reputational harm and loss of consumer confidence, regulatory & compliance repercussions etc.</p>
							</section>

					</div>

				<!-- Footer -->
					<footer id="footer">
						<section>
							<h3> References</h3>
							<P>Rudin, C. (2019) Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead, Nature News. Available at: https://www.nature.com/articles/s42256-019-0048-x (Accessed: 09 June 2023). </P>
							<p>Mittelstadt, B. et al. (2016) (PDF) The Ethics of Algorithms: Mapping the debate - researchgate, The Ethics of Algorithms: Mapping the Debate. Available at: https://www.researchgate.net/publication/309322060_The_Ethics_of_Algorithms_Mapping_the_Debate (Accessed: 09 June 2023). </p>
							<p>Mothukuri, V. et al. (2021) A survey on security and privacy of Federated Learning, Future Generation Computer Systems. Available at: https://www.sciencedirect.com/science/article/abs/pii/S0167739X20329848 (Accessed: 09 June 2023). </p>
						</section>
					</footer>

				<!-- Copyright -->
					<div id="copyright">
						<ul><li>&copy; html5up</li></ul>
					</div>

			</div>

					<!-- Scripts -->
					<script src="assets/js/jquery.min.js"></script>
					<script src="assets/js/jquery.scrollex.min.js"></script>
					<script src="assets/js/jquery.scrolly.min.js"></script>
					<script src="assets/js/browser.min.js"></script>
					<script src="assets/js/breakpoints.min.js"></script>
					<script src="assets/js/util.js"></script>
					<script src="assets/js/main.js"></script>
		

	</body>
</html>